{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The notebook is designed to show how to add any jdbc or driver jars to the classpath so it can be available for the libraries in the python code.</h3>\n",
    "<h3 align=\"right\">Author: Charles Gomes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20210414224234-0000\n",
      "KERNEL_ID = edb65b61-6bab-44b3-a3e5-36a0a60a123e\n",
      "Collecting JayDeBeApi\n",
      "  Downloading JayDeBeApi-1.2.3-py3-none-any.whl (26 kB)\n",
      "Collecting JPype1; python_version > \"2.7\" and platform_python_implementation != \"Jython\"\n",
      "  Downloading JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457 kB)\n",
      "\u001b[K     |████████████████████████████████| 457 kB 31.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: typing-extensions, JPype1, JayDeBeApi\n",
      "Successfully installed JPype1-1.2.1 JayDeBeApi-1.2.3 typing-extensions-3.7.4.3\n",
      "Collecting jpype1\n",
      "  Using cached JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457 kB)\n",
      "Collecting typing-extensions; python_version < \"3.8\"\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: typing-extensions, jpype1\n",
      "Successfully installed jpype1-1.2.1 typing-extensions-3.7.4.3\n",
      "\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/JPype1-1.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/jpype already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/org.jpype.jar already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/_jpype.cpython-37m-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/typing_extensions-3.7.4.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/spark/shared/user-libs/python3.7/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Install Jaydebapi to connect using jdbc and jpype1 to update the classpath\n",
    "!pip install JayDeBeApi\n",
    "!pip install jpype1\n",
    "#Note:- If you are using watson studio on cloud, you can actually preinstall this libaries in using environment customization so that you do not need to restart\n",
    "# the kernel after the installation of the libraries in case you need to run this notebooks as jobs\n",
    "# Customization:- https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/customize-envs.html?audience=wdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may need to restart the kernel in order to proceed ahead as this install libraries needs to be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of jaydebeapi :- 1.2.3\n",
      "Version of jpype :- 1.2.1\n"
     ]
    }
   ],
   "source": [
    "import jaydebeapi\n",
    "import jpype\n",
    "\n",
    "print(\"Version of jaydebeapi :- \" + jaydebeapi.__version__ )\n",
    "print(\"Version of jpype :- \" + jpype.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify if you have the minimum jaydebeapi >= 1.2.3 and jpype >= 1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ibm/connectors/idax/*:/opt/ibm/connectors/cloudant/*:/opt/ibm/connectors/db2/*:/opt/ibm/connectors/others-db-drivers/*:/opt/ibm/connectors/stocator/*:/opt/ibm/connectors/s3/*:/opt/ibm/image-libs/common/*:/opt/ibm/image-libs/spark2/*:/opt/ibm/third-party/libs/batch/*\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CLASSPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-14 22:42:41--  https://github.com/timveil/hive-jdbc-uber-jar/releases/download/v1.9-2.6.5/hive-jdbc-uber-2.6.5.0-292.jar\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/25035558/93863e8e-7fb4-11e8-80fb-501f8175b8a1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210414%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210414T224242Z&X-Amz-Expires=300&X-Amz-Signature=e3986a4d0ef20740b45790d5db5a4fcc7d9d4ea4ce6949f8131c407f33d85af8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=25035558&response-content-disposition=attachment%3B%20filename%3Dhive-jdbc-uber-2.6.5.0-292.jar&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-04-14 22:42:42--  https://github-releases.githubusercontent.com/25035558/93863e8e-7fb4-11e8-80fb-501f8175b8a1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210414%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210414T224242Z&X-Amz-Expires=300&X-Amz-Signature=e3986a4d0ef20740b45790d5db5a4fcc7d9d4ea4ce6949f8131c407f33d85af8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=25035558&response-content-disposition=attachment%3B%20filename%3Dhive-jdbc-uber-2.6.5.0-292.jar&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.111.154, 185.199.109.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18522029 (18M) [application/octet-stream]\n",
      "Saving to: ‘myjars/hive-jdbc-uber-2.6.5.0-292.jar’\n",
      "\n",
      "hive-jdbc-uber-2.6. 100%[===================>]  17.66M  42.9MB/s    in 0.4s    \n",
      "\n",
      "2021-04-14 22:42:43 (42.9 MB/s) - ‘myjars/hive-jdbc-uber-2.6.5.0-292.jar’ saved [18522029/18522029]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#In this example we are trying to connect to hive on IBM Analytics Engine or any Hadoop hive environment using jaydebeapi library which needs org.apache.hive.jdbc.HiveDriver class jar in classpath\n",
    "#Make a directory under your home directory and Download the jar file using wget to that directory\n",
    "!mkdir myjars;wget https://github.com/timveil/hive-jdbc-uber-jar/releases/download/v1.9-2.6.5/hive-jdbc-uber-2.6.5.0-292.jar -P myjars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/spark/shared'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Now we will use jpype to add this jar to the classpath and will start the JVM so that this jar will be available to JVM that python libraries will use ahead\n",
    "if jpype.isJVMStarted():\n",
    "    jpype.shutdownJVM()\n",
    "print(jpype.isJVMStarted())\n",
    "#check if jvm is already started. You may want to stop the jvm your environment is already loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the location of jar file to classpath\n",
    "import os\n",
    "jpype.addClassPath(os.getcwd()+\"/myjars/hive-jdbc-uber-2.6.5.0-292.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/spark/shared/myjars/hive-jdbc-uber-2.6.5.0-292.jar:/opt/ibm/connectors/idax/idax_spark_dsx-0.0.1-SNAPSHOT.jar:/opt/ibm/connectors/cloudant/cloudant-http-2.17.0.jar:/opt/ibm/connectors/cloudant/cloudant-client-2.17.0.jar:/opt/ibm/connectors/cloudant/spark-sql-cloudant_2.12-2.4.0.jar:/opt/ibm/connectors/cloudant/config-1.3.4.jar:/opt/ibm/connectors/cloudant/play-json_2.12-2.7.4.jar:/opt/ibm/connectors/db2/db2jcc.jar:/opt/ibm/connectors/db2/db2jcc_license_cisuz.jar:/opt/ibm/connectors/db2/db2jcc4.jar:/opt/ibm/connectors/others-db-drivers/wdp-connect-driver-cassandra-6.0.0.0304.jar:/opt/ibm/connectors/others-db-drivers/ojdbc8.jar:/opt/ibm/connectors/others-db-drivers/mysql.jar:/opt/ibm/connectors/others-db-drivers/postgresql-42.2.8.jar:/opt/ibm/connectors/others-db-drivers/nzjdbc3.jar:/opt/ibm/connectors/others-db-drivers/mssql-jdbc-7.4.1.jre8.jar:/opt/ibm/connectors/others-db-drivers/wdp-connect-driver-mysql-community-8.0.21.jar:/opt/ibm/connectors/others-db-drivers/ifxjdbc.jar:/opt/ibm/connectors/others-db-drivers/cassandra.jar:/opt/ibm/connectors/others-db-drivers/ojdbc.jar:/opt/ibm/connectors/stocator/stocator-1.1.3-IBM-SDK.jar:/opt/ibm/connectors/s3/hadoop-aws-2.7.3.jar:/opt/ibm/connectors/s3/aws-java-sdk-1.7.4.jar:/opt/ibm/image-libs/spark2/xskipper-core.jar:/opt/ibm/image-libs/spark2/xgboost4j-0.90.jar:/opt/ibm/image-libs/spark2/dsx-core-utils-scala.jar:/opt/ibm/image-libs/spark2/project-lib-semijar-assembly_2.12-1.1.7.jar:/opt/ibm/image-libs/spark2/systemml-0.14.0-incubating.jar:/opt/ibm/image-libs/spark2/sparksqlspatial-3.0.1.jar:/opt/ibm/image-libs/spark2/ibmos2spark_2.12-1.0.0-dev.jar:/opt/ibm/image-libs/spark2/spark-time-series-assembly-2.0.5_spark_3.0-jar-with-dependencies.jar:/opt/ibm/image-libs/spark2/xskipper-core_2.12-1.2.1.jar:/opt/ibm/image-libs/spark2/stmetaindexplugin.jar:/opt/ibm/image-libs/spark2/tika-parsers-1.14.jar:/opt/ibm/image-libs/spark2/xgboost4j-spark-0.90.jar:/opt/ibm/image-libs/spark2/DSX_spark_monitor_common.jar:/opt/ibm/image-libs/spark2/stmetaindexplugin_2.12-6.2.0.jar:/opt/ibm/image-libs/spark2/tika-app-1.14.jar:/opt/ibm/image-libs/spark2/metaindexmanager_2.12-6.2.0.jar:/opt/ibm/image-libs/spark2/stmetaindexplugin_2.12-6.1.0.jar:/opt/ibm/image-libs/spark2/spark-xml_2.11-0.8.0.jar:/opt/ibm/image-libs/spark2/DSX_spark_monitor_2.11.jar:/opt/ibm/image-libs/spark2/metaindexmanager.jar:/opt/ibm/image-libs/spark2/tika-core-1.14.jar:/opt/ibm/image-libs/spark2/time-series-assembly-iae-2.0.5_scala_2.12.jar:/opt/ibm/image-libs/spark2/spatiotemporal-core-1.3.0.jar'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify if the location is added\n",
    "jpype.getClassPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the jvm so that it will be preloaded with the classpath we created and ready for python libraries to use\n",
    "jpype.startJVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpype.isJVMStarted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the hive server and execute show tables\n",
    "import jaydebeapi\n",
    "conn = jaydebeapi.connect(\"org.apache.hive.jdbc.HiveDriver\",\"jdbc:hive2://<hive-host>:8443/;ssl=true;transportMode=http;httpPath=gateway/default/hive\",[\"<username>\", \"<password>\"])\n",
    "curs = conn.cursor();\n",
    "curs.execute(\"show databases\");\n",
    "print(curs.fetchall())\n",
    "print(curs.description)\n",
    "curs.execute(\"use sample\");\n",
    "#curs.execute(\"show tables\");\n",
    "curs.execute(\"show tables LIKE 'test*'\");\n",
    "print(curs.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 with Spark",
   "language": "python3",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
